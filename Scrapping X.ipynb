{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DhaniAAA/Scrapping-X/blob/main/Scrapping%20X.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Wajib Install\n",
        "# Install library Python yang dibutuhkan\n",
        "!pip install selenium pandas webdriver-manager\n",
        "\n",
        "# Download dan install Google Chrome\n",
        "!wget https://dl.google.com/linux/direct/google-chrome-stable_current_amd64.deb\n",
        "!dpkg -i google-chrome-stable_current_amd64.deb\n",
        "\n",
        "# Jika ada error dependensi, jalankan perintah ini untuk memperbaikinya\n",
        "!apt-get install -f"
      ],
      "metadata": {
        "collapsed": true,
        "id": "IUeOyGqHYcfG",
        "outputId": "3a04ac82-09a7-4150-b3dc-3096c60d3dff",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: selenium in /usr/local/lib/python3.11/dist-packages (4.34.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: webdriver-manager in /usr/local/lib/python3.11/dist-packages (4.0.2)\n",
            "Requirement already satisfied: urllib3~=2.5.0 in /usr/local/lib/python3.11/dist-packages (from urllib3[socks]~=2.5.0->selenium) (2.5.0)\n",
            "Requirement already satisfied: trio~=0.30.0 in /usr/local/lib/python3.11/dist-packages (from selenium) (0.30.0)\n",
            "Requirement already satisfied: trio-websocket~=0.12.2 in /usr/local/lib/python3.11/dist-packages (from selenium) (0.12.2)\n",
            "Requirement already satisfied: certifi>=2025.6.15 in /usr/local/lib/python3.11/dist-packages (from selenium) (2025.7.14)\n",
            "Requirement already satisfied: typing_extensions~=4.14.0 in /usr/local/lib/python3.11/dist-packages (from selenium) (4.14.1)\n",
            "Requirement already satisfied: websocket-client~=1.8.0 in /usr/local/lib/python3.11/dist-packages (from selenium) (1.8.0)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from webdriver-manager) (2.32.3)\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.11/dist-packages (from webdriver-manager) (1.1.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from webdriver-manager) (25.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: attrs>=23.2.0 in /usr/local/lib/python3.11/dist-packages (from trio~=0.30.0->selenium) (25.3.0)\n",
            "Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.11/dist-packages (from trio~=0.30.0->selenium) (2.4.0)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from trio~=0.30.0->selenium) (3.10)\n",
            "Requirement already satisfied: outcome in /usr/local/lib/python3.11/dist-packages (from trio~=0.30.0->selenium) (1.3.0.post0)\n",
            "Requirement already satisfied: sniffio>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from trio~=0.30.0->selenium) (1.3.1)\n",
            "Requirement already satisfied: wsproto>=0.14 in /usr/local/lib/python3.11/dist-packages (from trio-websocket~=0.12.2->selenium) (1.2.0)\n",
            "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in /usr/local/lib/python3.11/dist-packages (from urllib3[socks]~=2.5.0->selenium) (1.7.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->webdriver-manager) (3.4.2)\n",
            "Requirement already satisfied: h11<1,>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from wsproto>=0.14->trio-websocket~=0.12.2->selenium) (0.16.0)\n",
            "--2025-07-23 12:26:38--  https://dl.google.com/linux/direct/google-chrome-stable_current_amd64.deb\n",
            "Resolving dl.google.com (dl.google.com)... 173.194.64.136, 173.194.64.93, 173.194.64.91, ...\n",
            "Connecting to dl.google.com (dl.google.com)|173.194.64.136|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 118146996 (113M) [application/x-debian-package]\n",
            "Saving to: ‘google-chrome-stable_current_amd64.deb.1’\n",
            "\n",
            "google-chrome-stabl 100%[===================>] 112.67M   352MB/s    in 0.3s    \n",
            "\n",
            "2025-07-23 12:26:39 (352 MB/s) - ‘google-chrome-stable_current_amd64.deb.1’ saved [118146996/118146996]\n",
            "\n",
            "(Reading database ... 126440 files and directories currently installed.)\n",
            "Preparing to unpack google-chrome-stable_current_amd64.deb ...\n",
            "Unpacking google-chrome-stable (138.0.7204.168-1) over (138.0.7204.168-1) ...\n",
            "Setting up google-chrome-stable (138.0.7204.168-1) ...\n",
            "Processing triggers for mailcap (3.70+nmu1ubuntu1) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "0 upgraded, 0 newly installed, 0 to remove and 35 not upgraded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install selenium pandas webdriver-manager"
      ],
      "metadata": {
        "collapsed": true,
        "id": "HryIO2sBCQRk",
        "outputId": "f9f92469-5e90-4a9e-d482-83a83bca3bea",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: selenium in /usr/local/lib/python3.11/dist-packages (4.34.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: webdriver-manager in /usr/local/lib/python3.11/dist-packages (4.0.2)\n",
            "Requirement already satisfied: urllib3~=2.5.0 in /usr/local/lib/python3.11/dist-packages (from urllib3[socks]~=2.5.0->selenium) (2.5.0)\n",
            "Requirement already satisfied: trio~=0.30.0 in /usr/local/lib/python3.11/dist-packages (from selenium) (0.30.0)\n",
            "Requirement already satisfied: trio-websocket~=0.12.2 in /usr/local/lib/python3.11/dist-packages (from selenium) (0.12.2)\n",
            "Requirement already satisfied: certifi>=2025.6.15 in /usr/local/lib/python3.11/dist-packages (from selenium) (2025.7.14)\n",
            "Requirement already satisfied: typing_extensions~=4.14.0 in /usr/local/lib/python3.11/dist-packages (from selenium) (4.14.1)\n",
            "Requirement already satisfied: websocket-client~=1.8.0 in /usr/local/lib/python3.11/dist-packages (from selenium) (1.8.0)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from webdriver-manager) (2.32.3)\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.11/dist-packages (from webdriver-manager) (1.1.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from webdriver-manager) (25.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: attrs>=23.2.0 in /usr/local/lib/python3.11/dist-packages (from trio~=0.30.0->selenium) (25.3.0)\n",
            "Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.11/dist-packages (from trio~=0.30.0->selenium) (2.4.0)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from trio~=0.30.0->selenium) (3.10)\n",
            "Requirement already satisfied: outcome in /usr/local/lib/python3.11/dist-packages (from trio~=0.30.0->selenium) (1.3.0.post0)\n",
            "Requirement already satisfied: sniffio>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from trio~=0.30.0->selenium) (1.3.1)\n",
            "Requirement already satisfied: wsproto>=0.14 in /usr/local/lib/python3.11/dist-packages (from trio-websocket~=0.12.2->selenium) (1.2.0)\n",
            "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in /usr/local/lib/python3.11/dist-packages (from urllib3[socks]~=2.5.0->selenium) (1.7.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->webdriver-manager) (3.4.2)\n",
            "Requirement already satisfied: h11<1,>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from wsproto>=0.14->trio-websocket~=0.12.2->selenium) (0.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import pandas as pd\n",
        "from selenium import webdriver\n",
        "from selenium.webdriver.common.by import By\n",
        "from selenium.webdriver.chrome.service import Service\n",
        "from selenium.webdriver.chrome.options import Options\n",
        "from selenium.webdriver.support.ui import WebDriverWait\n",
        "from selenium.webdriver.support import expected_conditions as EC\n",
        "from selenium.common.exceptions import TimeoutException, WebDriverException\n",
        "from webdriver_manager.chrome import ChromeDriverManager\n",
        "import datetime\n",
        "import tempfile\n",
        "import shutil\n",
        "\n",
        "# --- KONFIGURASI ---\n",
        "# SALIN DAN TEMPEL NILAI `auth_token` ANDA DI BAWAH INI.\n",
        "# JANGAN BAGIKAN SCRIPT INI DENGAN COOKIE ANDA KARENA BERSIFAT RAHASIA.\n",
        "AUTH_TOKEN_COOKIE = \"2dd44a83f0c551d680e1052016e48921615bc68c\"\n",
        "\n",
        "# Waktu tunggu (dalam detik) antara setiap scroll agar halaman sempat memuat\n",
        "SCROLL_PAUSE_TIME = 5 # Direkomendasikan untuk menaikkan jeda untuk scraping jangka panjang\n",
        "# --------------------\n",
        "\n",
        "\n",
        "def setup_driver():\n",
        "    \"\"\"Menyiapkan instance WebDriver untuk Chrome tanpa user-data-dir (agar kompatibel dengan Colab).\"\"\"\n",
        "    print(\"Mencoba menyiapkan WebDriver...\")\n",
        "    chrome_options = Options()\n",
        "\n",
        "    # Gunakan mode headless di Colab\n",
        "    chrome_options.add_argument(\"--headless=new\")  # Gunakan --headless=new agar lebih stabil\n",
        "    chrome_options.add_argument(\"--no-sandbox\")\n",
        "    chrome_options.add_argument(\"--disable-dev-shm-usage\")\n",
        "    chrome_options.add_argument(\"--disable-gpu\")\n",
        "    chrome_options.add_argument(\"--window-size=1920,1080\")\n",
        "    chrome_options.add_argument(\"--log-level=3\")\n",
        "    chrome_options.add_argument('user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36')\n",
        "\n",
        "    try:\n",
        "        service = Service(ChromeDriverManager().install())\n",
        "        driver = webdriver.Chrome(service=service, options=chrome_options)\n",
        "        print(\"WebDriver berhasil disiapkan.\")\n",
        "        return driver, None\n",
        "    except (WebDriverException, ValueError) as e:\n",
        "        print(\"Error saat menyiapkan WebDriver.\")\n",
        "        print(f\"Detail error: {e}\")\n",
        "        return None, None\n",
        "\n",
        "\n",
        "def scrape_tweets(driver, query, target_count, search_type):\n",
        "    \"\"\"\n",
        "    Mengekstrak data tweet dari halaman pencarian untuk satu sesi.\n",
        "    \"\"\"\n",
        "    # Membuat URL dasar\n",
        "    search_url = f\"https://x.com/search?q={query}&src=typed_query\"\n",
        "    # Menambahkan parameter jika pengguna memilih 'Terbaru' ('live')\n",
        "    if search_type == 'latest':\n",
        "        search_url += \"&f=live\"\n",
        "\n",
        "    print(f\"Mengunjungi halaman pencarian: {search_url}\")\n",
        "    driver.get(search_url)\n",
        "\n",
        "    try:\n",
        "        # Menunggu elemen tweet pertama muncul\n",
        "        WebDriverWait(driver, 20).until(\n",
        "            EC.presence_of_element_located((By.XPATH, \"//article[@data-testid='tweet']\"))\n",
        "        )\n",
        "        print(\"Konten tweet terdeteksi. Memulai proses pengambilan data.\")\n",
        "    except TimeoutException:\n",
        "        print(\"Batas waktu menunggu habis. Tidak ada tweet yang ditemukan untuk sesi ini.\")\n",
        "        print(\"Ini bisa terjadi jika tidak ada tweet pada rentang tanggal ini atau karena masalah jaringan.\")\n",
        "        return []\n",
        "\n",
        "    # --- Scroll hingga target tercapai ---\n",
        "    tweets_data = {}\n",
        "    last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
        "    scroll_attempts = 0\n",
        "\n",
        "    while len(tweets_data) < target_count:\n",
        "        print(f\"\\nTweet terkumpul sesi ini: {len(tweets_data)}/{target_count}. Melakukan scroll...\")\n",
        "\n",
        "        tweet_articles = driver.find_elements(By.XPATH, \"//article[@data-testid='tweet']\")\n",
        "\n",
        "        for tweet in tweet_articles:\n",
        "            try:\n",
        "                # Menggunakan URL sebagai ID unik untuk menghindari duplikasi\n",
        "                tweet_url_elements = tweet.find_elements(By.XPATH, \".//a[contains(@href, '/status/')]\")\n",
        "                tweet_url = tweet_url_elements[0].get_attribute('href') if tweet_url_elements else None\n",
        "\n",
        "                if tweet_url and tweet_url not in tweets_data:\n",
        "                    username = tweet.find_element(By.XPATH, \".//div[@data-testid='User-Name']//span\").text\n",
        "                    handle = tweet.find_element(By.XPATH, \".//span[contains(text(), '@')]\").text\n",
        "                    timestamp = tweet.find_element(By.XPATH, \".//time\").get_attribute('datetime')\n",
        "                    tweet_text = tweet.find_element(By.XPATH, \".//div[@data-testid='tweetText']\").text.replace('\\n', ' ')\n",
        "                    reply_count = tweet.find_element(By.XPATH, \".//button[@data-testid='reply']\").text or \"0\"\n",
        "                    retweet_count = tweet.find_element(By.XPATH, \".//button[@data-testid='retweet']\").text or \"0\"\n",
        "                    like_count = tweet.find_element(By.XPATH, \".//button[@data-testid='like']\").text or \"0\"\n",
        "\n",
        "                    tweets_data[tweet_url] = {\n",
        "                        \"username\": username, \"handle\": handle, \"timestamp\": timestamp,\n",
        "                        \"tweet_text\": tweet_text, \"url\": tweet_url, \"reply_count\": reply_count,\n",
        "                        \"retweet_count\": retweet_count, \"like_count\": like_count\n",
        "                    }\n",
        "            except Exception:\n",
        "                continue\n",
        "\n",
        "        if len(tweets_data) >= target_count:\n",
        "            print(f\"Target {target_count} tweet untuk sesi ini telah tercapai.\")\n",
        "            break\n",
        "\n",
        "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
        "        time.sleep(SCROLL_PAUSE_TIME)\n",
        "\n",
        "        new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
        "        if new_height == last_height:\n",
        "            scroll_attempts += 1\n",
        "            print(\"Sudah mencapai akhir halaman untuk sesi ini...\")\n",
        "            if scroll_attempts > 3:\n",
        "                print(\"Tidak ada tweet baru yang dimuat. Mengakhiri sesi ini.\")\n",
        "                break\n",
        "        else:\n",
        "            scroll_attempts = 0\n",
        "        last_height = new_height\n",
        "\n",
        "    return list(tweets_data.values())[:target_count]\n",
        "\n",
        "def get_user_input():\n",
        "    \"\"\"Meminta input dari pengguna untuk parameter pencarian.\"\"\"\n",
        "    keyword = input(\"1. Masukkan kata kunci/topik pencarian: \")\n",
        "\n",
        "    while True:\n",
        "        try:\n",
        "            target_count = int(input(\"2. Berapa jumlah MAKSIMAL tweet yang ingin diambil PER SESI? \"))\n",
        "            if target_count > 0:\n",
        "                break\n",
        "            else:\n",
        "                print(\"Jumlah harus lebih dari 0.\")\n",
        "        except ValueError:\n",
        "            print(\"Input tidak valid, masukkan angka.\")\n",
        "\n",
        "    while True:\n",
        "        start_date_str = input(\"3. Masukkan TANGGAL MULAI KESELURUHAN (YYYY-MM-DD): \")\n",
        "        try:\n",
        "            start_date_obj = datetime.datetime.strptime(start_date_str, '%Y-%m-%d')\n",
        "            break\n",
        "        except ValueError:\n",
        "            print(\"Format tanggal salah. Gunakan format YYYY-MM-DD.\")\n",
        "\n",
        "    while True:\n",
        "        end_date_str = input(\"4. Masukkan TANGGAL SELESAI KESELURUHAN (YYYY-MM-DD): \")\n",
        "        try:\n",
        "            end_date_obj = datetime.datetime.strptime(end_date_str, '%Y-%m-%d')\n",
        "            if end_date_obj >= start_date_obj:\n",
        "                break\n",
        "            else:\n",
        "                print(\"Tanggal selesai harus sama atau setelah tanggal mulai.\")\n",
        "        except ValueError:\n",
        "            print(\"Format tanggal salah. Gunakan format YYYY-MM-DD.\")\n",
        "\n",
        "    while True:\n",
        "        try:\n",
        "            interval_days = int(input(\"5. Berapa hari interval per sesi scraping? (misal: 1 untuk per hari): \"))\n",
        "            if interval_days > 0:\n",
        "                break\n",
        "            else:\n",
        "                print(\"Interval harus lebih dari 0.\")\n",
        "        except ValueError:\n",
        "            print(\"Input tidak valid, masukkan angka.\")\n",
        "\n",
        "    lang = input(\"6. Masukkan kode bahasa (misal: 'id' untuk Indonesia, 'en' untuk Inggris): \")\n",
        "\n",
        "    while True:\n",
        "        choice = input(\"7. Pilih jenis tweet (1 untuk Top, 2 untuk Terbaru): \")\n",
        "        if choice == '1':\n",
        "            search_type = 'top'\n",
        "            break\n",
        "        elif choice == '2':\n",
        "            search_type = 'latest'\n",
        "            break\n",
        "        else:\n",
        "            print(\"Input tidak valid. Masukkan 1 atau 2.\")\n",
        "\n",
        "    return keyword, target_count, start_date_obj, end_date_obj, interval_days, lang, search_type\n",
        "\n",
        "def main():\n",
        "    \"\"\"Fungsi utama untuk menjalankan proses scraping secara berulang per interval tanggal.\"\"\"\n",
        "    if not AUTH_TOKEN_COOKIE or AUTH_TOKEN_COOKIE == \"Ganti dengan punya kalian\":\n",
        "        print(\"Error: Harap isi variabel AUTH_TOKEN_COOKIE dengan nilai cookie Anda.\")\n",
        "        return\n",
        "\n",
        "    (keyword, target_per_session, start_date, end_date,\n",
        "     interval, lang, search_type) = get_user_input()\n",
        "\n",
        "    driver, user_data_dir = setup_driver()\n",
        "    if not driver:\n",
        "        return\n",
        "\n",
        "    try:\n",
        "        # --- Login sekali saja di awal ---\n",
        "        print(\"Mengunjungi x.com untuk menyuntikkan cookie login...\")\n",
        "        driver.get(\"https://x.com\")\n",
        "        time.sleep(2)\n",
        "        if AUTH_TOKEN_COOKIE and AUTH_TOKEN_COOKIE != \"Ganti dengan punya kalian\":\n",
        "            cookie = {'name': 'auth_token', 'value': AUTH_TOKEN_COOKIE, 'domain': '.x.com'}\n",
        "            driver.add_cookie(cookie)\n",
        "            print(\"Cookie berhasil disuntikkan.\")\n",
        "        else:\n",
        "            print(\"PERINGATAN: Cookie tidak diatur. Script mungkin akan terhadang halaman login.\")\n",
        "\n",
        "        all_scraped_data = []\n",
        "        current_date = start_date\n",
        "\n",
        "        # --- Loop utama untuk scraping per interval ---\n",
        "        while current_date <= end_date:\n",
        "            chunk_end_date = current_date + datetime.timedelta(days=interval)\n",
        "\n",
        "            since_str = current_date.strftime('%Y-%m-%d')\n",
        "            until_str = chunk_end_date.strftime('%Y-%m-%d')\n",
        "\n",
        "            print(\"\\n\" + \"=\"*50)\n",
        "            print(f\"--- MEMULAI SESI UNTUK TANGGAL: {since_str} hingga {until_str} ---\")\n",
        "            print(\"=\"*50)\n",
        "\n",
        "            search_query = f\"{keyword} lang:{lang} until:{until_str} since:{since_str}\"\n",
        "\n",
        "            session_data = scrape_tweets(driver, search_query, target_per_session, search_type)\n",
        "\n",
        "            if session_data:\n",
        "                all_scraped_data.extend(session_data)\n",
        "\n",
        "            print(f\"\\nSesi untuk {since_str} - {until_str} selesai.\")\n",
        "            print(f\"Total tweet terkumpul sejauh ini: {len(all_scraped_data)}\")\n",
        "\n",
        "            current_date = chunk_end_date\n",
        "\n",
        "            if current_date <= end_date:\n",
        "                print(\"Memberi jeda 10 detik sebelum sesi berikutnya...\")\n",
        "                time.sleep(10)\n",
        "\n",
        "        # --- Proses setelah semua sesi selesai ---\n",
        "        if not all_scraped_data:\n",
        "            print(\"\\nTidak ada data yang berhasil diambil dari seluruh sesi.\")\n",
        "            return\n",
        "\n",
        "        print(\"\\n--- SEMUA SESI SELESAI ---\")\n",
        "        print(\"Menggabungkan dan membersihkan data duplikat...\")\n",
        "\n",
        "        df = pd.DataFrame(all_scraped_data)\n",
        "        df.drop_duplicates(subset=['url'], inplace=True, keep='first')\n",
        "\n",
        "        safe_keyword = \"\".join(c for c in keyword if c.isalnum())\n",
        "        output_filename = f\"tweets_{safe_keyword}_{search_type}_{start_date.strftime('%Y%m%d')}-{end_date.strftime('%Y%m%d')}.csv\"\n",
        "        df.to_csv(output_filename, index=False, encoding='utf-8-sig')\n",
        "\n",
        "        print(f\"\\n--- PROSES SELESAI ---\")\n",
        "        print(f\"Data telah disimpan di file: {output_filename}\")\n",
        "        print(f\"Total tweet unik yang berhasil diambil: {len(df)}\")\n",
        "        print(\"\\nContoh data:\")\n",
        "        print(df.head())\n",
        "\n",
        "    finally:\n",
        "        if driver:\n",
        "            print(\"\\nMenutup browser...\")\n",
        "            driver.quit()\n",
        "        # Membersihkan direktori sementara setelah driver ditutup\n",
        "        if user_data_dir:\n",
        "            print(f\"Membersihkan direktori sementara: {user_data_dir}\")\n",
        "            shutil.rmtree(user_data_dir, ignore_errors=True)\n",
        "\n",
        "    print(\"\\nEksekusi skrip telah selesai. Program sekarang akan berhenti.\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "GEATvZOYeiK2",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"/content/tweets_tomlembong_top_20250501-20250520.csv\")\n",
        "df"
      ],
      "metadata": {
        "id": "wuqV2IFYhfHf",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "Selamat Datang di Colab",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}