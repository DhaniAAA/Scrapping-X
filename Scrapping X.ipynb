{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DhaniAAA/Scrapping-X/blob/main/Scrapping%20X.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Wajib Install\n",
        "# Install library Python yang dibutuhkan\n",
        "!pip install selenium pandas webdriver-manager\n",
        "\n",
        "# Download dan install Google Chrome\n",
        "!wget https://dl.google.com/linux/direct/google-chrome-stable_current_amd64.deb\n",
        "!dpkg -i google-chrome-stable_current_amd64.deb\n",
        "\n",
        "# Jika ada error dependensi, jalankan perintah ini untuk memperbaikinya\n",
        "!apt-get install -f"
      ],
      "metadata": {
        "collapsed": true,
        "id": "IUeOyGqHYcfG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install selenium pandas webdriver-manager"
      ],
      "metadata": {
        "collapsed": true,
        "id": "HryIO2sBCQRk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import pandas as pd\n",
        "from urllib.parse import quote\n",
        "from selenium import webdriver\n",
        "from selenium.webdriver.common.by import By\n",
        "from selenium.webdriver.chrome.service import Service\n",
        "from selenium.webdriver.chrome.options import Options\n",
        "from selenium.webdriver.support.ui import WebDriverWait\n",
        "from selenium.webdriver.support import expected_conditions as EC\n",
        "from selenium.common.exceptions import TimeoutException, WebDriverException\n",
        "from webdriver_manager.chrome import ChromeDriverManager\n",
        "import datetime\n",
        "import tempfile\n",
        "import shutil\n",
        "\n",
        "# --- KONFIGURASI ---\n",
        "# SALIN DAN TEMPEL NILAI `auth_token` ANDA DI BAWAH INI.\n",
        "# JANGAN BAGIKAN SCRIPT INI DENGAN COOKIE ANDA KARENA BERSIFAT RAHASIA.\n",
        "AUTH_TOKEN_COOKIE = \"cookie kalian\"\n",
        "\n",
        "# Waktu tunggu (dalam detik) antara setiap scroll agar halaman sempat memuat\n",
        "SCROLL_PAUSE_TIME = 5 # Direkomendasikan untuk menaikkan jeda untuk scraping jangka panjang\n",
        "# --------------------\n",
        "\n",
        "\n",
        "def setup_driver():\n",
        "    \"\"\"Menyiapkan instance WebDriver untuk Chrome tanpa user-data-dir (agar kompatibel dengan Colab).\"\"\"\n",
        "    print(\"Mencoba menyiapkan WebDriver...\")\n",
        "    chrome_options = Options()\n",
        "\n",
        "    # Gunakan mode headless di Colab\n",
        "    chrome_options.add_argument(\"--headless=new\")  # Gunakan --headless=new agar lebih stabil\n",
        "    chrome_options.add_argument(\"--no-sandbox\")\n",
        "    chrome_options.add_argument(\"--disable-dev-shm-usage\")\n",
        "    chrome_options.add_argument(\"--disable-gpu\")\n",
        "    chrome_options.add_argument(\"--window-size=1920,1080\")\n",
        "    chrome_options.add_argument(\"--log-level=3\")\n",
        "    chrome_options.add_argument('user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36')\n",
        "\n",
        "    try:\n",
        "        service = Service(ChromeDriverManager().install())\n",
        "        driver = webdriver.Chrome(service=service, options=chrome_options)\n",
        "        print(\"WebDriver berhasil disiapkan.\")\n",
        "        return driver, None\n",
        "    except (WebDriverException, ValueError) as e:\n",
        "        print(\"Error saat menyiapkan WebDriver.\")\n",
        "        print(f\"Detail error: {e}\")\n",
        "        return None, None\n",
        "\n",
        "\n",
        "def scrape_tweets(driver, query, target_count, search_type):\n",
        "    \"\"\"\n",
        "    Mengekstrak data tweet dari halaman pencarian untuk satu sesi.\n",
        "    \"\"\"\n",
        "    # Membuat URL dasar\n",
        "    search_url = f\"https://x.com/search?q={query}&src=typed_query\"\n",
        "    # Menambahkan parameter jika pengguna memilih 'Terbaru' ('live')\n",
        "    if search_type == 'latest':\n",
        "        search_url += \"&f=live\"\n",
        "\n",
        "    print(f\"Mengunjungi halaman pencarian: {search_url}\")\n",
        "    driver.get(search_url)\n",
        "\n",
        "    try:\n",
        "        # Menunggu elemen tweet pertama muncul\n",
        "        WebDriverWait(driver, 20).until(\n",
        "            EC.presence_of_element_located((By.XPATH, \"//article[@data-testid='tweet']\"))\n",
        "        )\n",
        "        print(\"Konten tweet terdeteksi. Memulai proses pengambilan data.\")\n",
        "    except TimeoutException:\n",
        "        print(\"Batas waktu menunggu habis. Tidak ada tweet yang ditemukan untuk sesi ini.\")\n",
        "        print(\"Ini bisa terjadi jika tidak ada tweet pada rentang tanggal ini atau karena masalah jaringan.\")\n",
        "        return []\n",
        "\n",
        "    # --- Scroll hingga target tercapai ---\n",
        "    tweets_data = {}\n",
        "    last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
        "    scroll_attempts = 0\n",
        "\n",
        "    while len(tweets_data) < target_count:\n",
        "        print(f\"\\nTweet terkumpul sesi ini: {len(tweets_data)}/{target_count}. Melakukan scroll...\")\n",
        "\n",
        "        tweet_articles = driver.find_elements(By.XPATH, \"//article[@data-testid='tweet']\")\n",
        "\n",
        "        for tweet in tweet_articles:\n",
        "            try:\n",
        "                # Menggunakan URL sebagai ID unik untuk menghindari duplikasi\n",
        "                tweet_url_elements = tweet.find_elements(By.XPATH, \".//a[contains(@href, '/status/')]\")\n",
        "                tweet_url = tweet_url_elements[0].get_attribute('href') if tweet_url_elements else None\n",
        "\n",
        "                if tweet_url and tweet_url not in tweets_data:\n",
        "                    username = tweet.find_element(By.XPATH, \".//div[@data-testid='User-Name']//span\").text\n",
        "                    handle = tweet.find_element(By.XPATH, \".//span[contains(text(), '@')]\").text\n",
        "                    timestamp = tweet.find_element(By.XPATH, \".//time\").get_attribute('datetime')\n",
        "                    tweet_text = tweet.find_element(By.XPATH, \".//div[@data-testid='tweetText']\").text.replace('\\n', ' ')\n",
        "                    reply_count = tweet.find_element(By.XPATH, \".//button[@data-testid='reply']\").text or \"0\"\n",
        "                    retweet_count = tweet.find_element(By.XPATH, \".//button[@data-testid='retweet']\").text or \"0\"\n",
        "                    like_count = tweet.find_element(By.XPATH, \".//button[@data-testid='like']\").text or \"0\"\n",
        "\n",
        "                    tweets_data[tweet_url] = {\n",
        "                        \"username\": username, \"handle\": handle, \"timestamp\": timestamp,\n",
        "                        \"tweet_text\": tweet_text, \"url\": tweet_url, \"reply_count\": reply_count,\n",
        "                        \"retweet_count\": retweet_count, \"like_count\": like_count\n",
        "                    }\n",
        "            except Exception:\n",
        "                continue\n",
        "\n",
        "        if len(tweets_data) >= target_count:\n",
        "            print(f\"Target {target_count} tweet untuk sesi ini telah tercapai.\")\n",
        "            break\n",
        "\n",
        "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
        "        time.sleep(SCROLL_PAUSE_TIME)\n",
        "\n",
        "        new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
        "        if new_height == last_height:\n",
        "            scroll_attempts += 1\n",
        "            print(\"Sudah mencapai akhir halaman untuk sesi ini...\")\n",
        "            if scroll_attempts > 3:\n",
        "                print(\"Tidak ada tweet baru yang dimuat. Mengakhiri sesi ini.\")\n",
        "                break\n",
        "        else:\n",
        "            scroll_attempts = 0\n",
        "        last_height = new_height\n",
        "\n",
        "    return list(tweets_data.values())[:target_count]\n",
        "\n",
        "def get_user_input():\n",
        "    \"\"\"Meminta input dari pengguna untuk parameter pencarian.\"\"\"\n",
        "    keyword = input(\"1. Masukkan kata kunci/topik pencarian: \")\n",
        "\n",
        "    while True:\n",
        "        try:\n",
        "            target_count = int(input(\"2. Berapa jumlah MAKSIMAL tweet yang ingin diambil PER SESI? \"))\n",
        "            if target_count > 0:\n",
        "                break\n",
        "            else:\n",
        "                print(\"Jumlah harus lebih dari 0.\")\n",
        "        except ValueError:\n",
        "            print(\"Input tidak valid, masukkan angka.\")\n",
        "\n",
        "    while True:\n",
        "        start_date_str = input(\"3. Masukkan TANGGAL MULAI KESELURUHAN (YYYY-MM-DD): \")\n",
        "        try:\n",
        "            start_date_obj = datetime.datetime.strptime(start_date_str, '%Y-%m-%d')\n",
        "            break\n",
        "        except ValueError:\n",
        "            print(\"Format tanggal salah. Gunakan format YYYY-MM-DD.\")\n",
        "\n",
        "    while True:\n",
        "        end_date_str = input(\"4. Masukkan TANGGAL SELESAI KESELURUHAN (YYYY-MM-DD): \")\n",
        "        try:\n",
        "            end_date_obj = datetime.datetime.strptime(end_date_str, '%Y-%m-%d')\n",
        "            if end_date_obj >= start_date_obj:\n",
        "                break\n",
        "            else:\n",
        "                print(\"Tanggal selesai harus sama atau setelah tanggal mulai.\")\n",
        "        except ValueError:\n",
        "            print(\"Format tanggal salah. Gunakan format YYYY-MM-DD.\")\n",
        "\n",
        "    while True:\n",
        "        try:\n",
        "            interval_days = int(input(\"5. Berapa hari interval per sesi scraping? (misal: 1 untuk per hari): \"))\n",
        "            if interval_days > 0:\n",
        "                break\n",
        "            else:\n",
        "                print(\"Interval harus lebih dari 0.\")\n",
        "        except ValueError:\n",
        "            print(\"Input tidak valid, masukkan angka.\")\n",
        "\n",
        "    lang = input(\"6. Masukkan kode bahasa (misal: 'id' untuk Indonesia, 'en' untuk Inggris): \")\n",
        "\n",
        "    while True:\n",
        "        choice = input(\"7. Pilih jenis tweet (1 untuk Top, 2 untuk Terbaru): \")\n",
        "        if choice == '1':\n",
        "            search_type = 'top'\n",
        "            break\n",
        "        elif choice == '2':\n",
        "            search_type = 'latest'\n",
        "            break\n",
        "        else:\n",
        "            print(\"Input tidak valid. Masukkan 1 atau 2.\")\n",
        "\n",
        "    return keyword, target_count, start_date_obj, end_date_obj, interval_days, lang, search_type\n",
        "\n",
        "def main():\n",
        "    \"\"\"Fungsi utama untuk menjalankan proses scraping secara berulang per interval tanggal.\"\"\"\n",
        "    if not AUTH_TOKEN_COOKIE or AUTH_TOKEN_COOKIE == \"Ganti dengan punya kalian\":\n",
        "        print(\"Error: Harap isi variabel AUTH_TOKEN_COOKIE dengan nilai cookie Anda.\")\n",
        "        return\n",
        "\n",
        "    (keyword, target_per_session, start_date, end_date,\n",
        "     interval, lang, search_type) = get_user_input()\n",
        "\n",
        "    driver, user_data_dir = setup_driver()\n",
        "    if not driver:\n",
        "        return\n",
        "\n",
        "    try:\n",
        "        # --- Login sekali saja di awal ---\n",
        "        print(\"Mengunjungi x.com untuk menyuntikkan cookie login...\")\n",
        "        driver.get(\"https://x.com\")\n",
        "        time.sleep(2)\n",
        "        if AUTH_TOKEN_COOKIE and AUTH_TOKEN_COOKIE != \"Ganti dengan punya kalian\":\n",
        "            cookie = {'name': 'auth_token', 'value': AUTH_TOKEN_COOKIE, 'domain': '.x.com'}\n",
        "            driver.add_cookie(cookie)\n",
        "            print(\"Cookie berhasil disuntikkan.\")\n",
        "        else:\n",
        "            print(\"PERINGATAN: Cookie tidak diatur. Script mungkin akan terhadang halaman login.\")\n",
        "\n",
        "        all_scraped_data = []\n",
        "        current_date = start_date\n",
        "\n",
        "        # --- Loop utama untuk scraping per interval ---\n",
        "        while current_date <= end_date:\n",
        "            chunk_end_date = current_date + datetime.timedelta(days=interval)\n",
        "\n",
        "            since_str = current_date.strftime('%Y-%m-%d')\n",
        "            until_str = chunk_end_date.strftime('%Y-%m-%d')\n",
        "\n",
        "            print(\"\\n\" + \"=\"*50)\n",
        "            print(f\"--- MEMULAI SESI UNTUK TANGGAL: {since_str} hingga {until_str} ---\")\n",
        "            print(\"=\"*50)\n",
        "\n",
        "            search_query_raw = f\"{keyword} lang:{lang} until:{until_str} since:{since_str}\"\n",
        "            search_query = quote(search_query_raw)\n",
        "\n",
        "            session_data = scrape_tweets(driver, search_query, target_per_session, search_type)\n",
        "\n",
        "            if session_data:\n",
        "                all_scraped_data.extend(session_data)\n",
        "\n",
        "            print(f\"\\nSesi untuk {since_str} - {until_str} selesai.\")\n",
        "            print(f\"Total tweet terkumpul sejauh ini: {len(all_scraped_data)}\")\n",
        "\n",
        "            current_date = chunk_end_date\n",
        "\n",
        "            if current_date <= end_date:\n",
        "                print(\"Memberi jeda 10 detik sebelum sesi berikutnya...\")\n",
        "                time.sleep(10)\n",
        "\n",
        "        # --- Proses setelah semua sesi selesai ---\n",
        "        if not all_scraped_data:\n",
        "            print(\"\\nTidak ada data yang berhasil diambil dari seluruh sesi.\")\n",
        "            return\n",
        "\n",
        "        print(\"\\n--- SEMUA SESI SELESAI ---\")\n",
        "        print(\"Menggabungkan dan membersihkan data duplikat...\")\n",
        "\n",
        "        df = pd.DataFrame(all_scraped_data)\n",
        "        df.drop_duplicates(subset=['url'], inplace=True, keep='first')\n",
        "\n",
        "        safe_keyword = \"\".join(c for c in keyword if c.isalnum())\n",
        "        output_filename = f\"tweets_{safe_keyword}_{search_type}_{start_date.strftime('%Y%m%d')}-{end_date.strftime('%Y%m%d')}.csv\"\n",
        "        df.to_csv(output_filename, index=False, encoding='utf-8-sig')\n",
        "\n",
        "        print(f\"\\n--- PROSES SELESAI ---\")\n",
        "        print(f\"Data telah disimpan di file: {output_filename}\")\n",
        "        print(f\"Total tweet unik yang berhasil diambil: {len(df)}\")\n",
        "        print(\"\\nContoh data:\")\n",
        "        print(df.head())\n",
        "\n",
        "    finally:\n",
        "        if driver:\n",
        "            print(\"\\nMenutup browser...\")\n",
        "            driver.quit()\n",
        "        # Membersihkan direktori sementara setelah driver ditutup\n",
        "        if user_data_dir:\n",
        "            print(f\"Membersihkan direktori sementara: {user_data_dir}\")\n",
        "            shutil.rmtree(user_data_dir, ignore_errors=True)\n",
        "\n",
        "    print(\"\\nEksekusi skrip telah selesai. Program sekarang akan berhenti.\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "GEATvZOYeiK2",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"/content/tweets_tomlembong_top_20250501-20250520.csv\")\n",
        "df"
      ],
      "metadata": {
        "id": "wuqV2IFYhfHf",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "Selamat Datang di Colab",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}